{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T15:35:43.365419Z",
     "iopub.status.busy": "2025-02-14T15:35:43.364609Z",
     "iopub.status.idle": "2025-02-14T15:35:43.375798Z",
     "shell.execute_reply": "2025-02-14T15:35:43.374905Z",
     "shell.execute_reply.started": "2025-02-14T15:35:43.365381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd /kaggle/input/mancode1/MAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T15:35:43.379661Z",
     "iopub.status.busy": "2025-02-14T15:35:43.379417Z",
     "iopub.status.idle": "2025-02-14T15:36:07.348089Z",
     "shell.execute_reply": "2025-02-14T15:36:07.347184Z",
     "shell.execute_reply.started": "2025-02-14T15:35:43.379637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "from models.vgg_c import vgg19_trans\n",
    "import glob\n",
    "\n",
    "class VideoCrowdCounter:\n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        model = vgg19_trans()\n",
    "        model.load_state_dict(torch.load(model_path, self.device, weights_only=True))\n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        # Convert frame to PIL Image\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Transform image\n",
    "        img_tensor = self.transform(img).unsqueeze(0)\n",
    "        img_tensor = img_tensor.to(self.device)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            density_map, _ = self.model(img_tensor)\n",
    "        \n",
    "        # Process density map\n",
    "        density_map = density_map.squeeze().cpu().numpy()\n",
    "        count = np.sum(density_map)\n",
    "        \n",
    "        # Resize density map to match frame size\n",
    "        density_map = cv2.resize(density_map, (frame.shape[1], frame.shape[0]))\n",
    "        normalized_map = np.clip(density_map/np.max(density_map), 0, 1)\n",
    "        \n",
    "        # Create heatmap\n",
    "        heatmap = cv2.applyColorMap((normalized_map * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Create overlay\n",
    "        overlay = cv2.addWeighted(frame, 0.6, heatmap, 0.4, 0)\n",
    "        \n",
    "        # Add count text to original frame\n",
    "        count_frame = frame.copy()\n",
    "        cv2.putText(count_frame, f'Count: {int(count)}', (30, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        return count_frame, heatmap, overlay\n",
    "\n",
    "    def process_video(self, video_path, output_dir, fps=30):\n",
    "        # Get video name without extension\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Open video\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Error: Could not open video {video_path}\")\n",
    "                return None\n",
    "                \n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "            # Create output filenames\n",
    "            count_path = os.path.join(output_dir, f'{video_name}_count.mp4')\n",
    "            density_path = os.path.join(output_dir, f'{video_name}_density.mp4')\n",
    "            overlay_path = os.path.join(output_dir, f'{video_name}_overlay.mp4')\n",
    "            \n",
    "            # Create video writers\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            count_writer = cv2.VideoWriter(count_path, fourcc, fps, (width, height))\n",
    "            density_writer = cv2.VideoWriter(density_path, fourcc, fps, (width, height))\n",
    "            overlay_writer = cv2.VideoWriter(overlay_path, fourcc, fps, (width, height))\n",
    "            \n",
    "            # Process each frame\n",
    "            pbar = tqdm(total=total_frames, desc=f'Processing {video_name}')\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "                # Process frame\n",
    "                count_frame, density_map, overlay = self.process_frame(frame)\n",
    "                \n",
    "                # Write frames\n",
    "                count_writer.write(count_frame)\n",
    "                density_writer.write(density_map)\n",
    "                overlay_writer.write(overlay)\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            # Release everything\n",
    "            cap.release()\n",
    "            count_writer.release()\n",
    "            density_writer.release()\n",
    "            overlay_writer.release()\n",
    "            pbar.close()\n",
    "            \n",
    "            return [count_path, density_path, overlay_path]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {video_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def process_videos_in_directory(input_dir, model_path, output_dir):\n",
    "    # Initialize processor\n",
    "    processor = VideoCrowdCounter(model_path)\n",
    "    \n",
    "    # Get all video files\n",
    "    video_files = glob.glob(os.path.join(input_dir, \"*.mp4\")) + \\\n",
    "                 glob.glob(os.path.join(input_dir, \"*.avi\")) + \\\n",
    "                 glob.glob(os.path.join(input_dir, \"*.mov\"))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No video files found in {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    all_output_files = []\n",
    "    \n",
    "    # Process each video\n",
    "    for video_path in video_files:\n",
    "        output_files = processor.process_video(video_path, output_dir)\n",
    "        if output_files:\n",
    "            all_output_files.extend(output_files)\n",
    "    \n",
    "    # Create zip file if we have processed files\n",
    "    if all_output_files:\n",
    "        zip_path = os.path.join(output_dir, 'crowd_vid4.zip')\n",
    "        with ZipFile(zip_path, 'w') as zipf:\n",
    "            for file in all_output_files:\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file, os.path.basename(file))\n",
    "        print(f\"Results saved to {zip_path}\")\n",
    "    else:\n",
    "        print(\"No videos were successfully processed\")\n",
    "\n",
    "def main():\n",
    "    # Configure paths\n",
    "    input_dir = '/kaggle/input/stadium-vids'\n",
    "    model_path = '/kaggle/input/man-model/model.pth'\n",
    "    output_dir = '/kaggle/working'\n",
    "    \n",
    "    process_videos_in_directory(input_dir, model_path, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6401088,
     "sourceId": 10337372,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6432386,
     "sourceId": 10383641,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6432624,
     "sourceId": 10383970,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6667816,
     "sourceId": 10750840,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
